{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2743899a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Indonesian Hate Speech Detection - GUI Application Guide\n",
    "\n",
    "This notebook provides a guide for using the Indonesian Hate Speech Detection GUI application. The GUI application (`gui.py`) provides an easy-to-use interface for detecting hate speech in Indonesian text.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Prerequisites](#prerequisites)\n",
    "2. [Running the GUI Application](#running-the-gui)\n",
    "3. [GUI Features Overview](#features)\n",
    "4. [How to Use the Application](#usage)\n",
    "5. [Understanding Results](#results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b3ed4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Prerequisites\n",
    "\n",
    "Before running the GUI application, ensure you have:\n",
    "\n",
    "### Required Files\n",
    "The following files must exist in the `../models/` directory (one level up from notebooks):\n",
    "- `best_hate_speech_model.pkl` (trained machine learning model)\n",
    "- `tfidf_vectorizer.pkl` (text vectorizer)\n",
    "- `model_metadata.json` (model information)\n",
    "\n",
    "### Required Python Packages\n",
    "- `tkinter` (usually comes with Python installation)\n",
    "- `pandas`\n",
    "- `numpy`  \n",
    "- `scikit-learn`\n",
    "- `joblib`\n",
    "- `re` (built-in)\n",
    "- `threading` (built-in)\n",
    "\n",
    "Install missing packages using:\n",
    "```bash\n",
    "pip install pandas numpy scikit-learn joblib\n",
    "```\n",
    "\n",
    "### System Requirements\n",
    "- Python 3.6 or higher\n",
    "- Windows/Mac/Linux with GUI support\n",
    "- At least 2GB RAM (for model loading)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8cb5fe",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Running the GUI Application\n",
    "\n",
    "### Step 1: Navigate to the notebooks directory\n",
    "```bash\n",
    "cd notebooks\n",
    "```\n",
    "\n",
    "### Step 2: Run the GUI application\n",
    "```bash\n",
    "python gui.py\n",
    "```\n",
    "\n",
    "### What happens when you run it:\n",
    "1. The application will load models from `../models/`\n",
    "2. You'll see console messages indicating success or failure\n",
    "3. If successful, a GUI window will open automatically\n",
    "\n",
    "### Expected Console Output:\n",
    "```\n",
    "Script directory: C:\\Users\\...\\indonesian-hate-speech-detection\\notebooks\n",
    "Looking for models in: C:\\Users\\...\\indonesian-hate-speech-detection\\models\n",
    "Model file exists: True\n",
    "Vectorizer file exists: True\n",
    "Loading models...\n",
    "SUCCESS: Models loaded successfully\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea70f02",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. GUI Features Overview\n",
    "\n",
    "The Indonesian Hate Speech Detection GUI includes the following features:\n",
    "\n",
    "### Window Title\n",
    "**Indonesian Hate Speech Detector** / *Deteksi Ujaran Kebencian dalam Bahasa Indonesia*\n",
    "\n",
    "### Interface Sections\n",
    "\n",
    "#### Input Text Section\n",
    "- **Large text area**: For entering Indonesian text to analyze\n",
    "- **Placeholder text**: Shows example usage when empty\n",
    "- **Focus behavior**: Placeholder disappears when you click to type\n",
    "\n",
    "#### Control Buttons\n",
    "- **Analyze Text**: Performs hate speech detection analysis\n",
    "- **Clear**: Clears input text and resets results\n",
    "- **Example**: Loads example text for testing\n",
    "\n",
    "#### Analysis Results Section\n",
    "- **Prediction Result**: Shows classification with color coding\n",
    "- **Confidence Score**: Model confidence percentage\n",
    "- **Text Statistics**: Character, word, and sentence counts\n",
    "- **Processing Time**: Analysis duration in seconds\n",
    "\n",
    "### Visual Design Elements\n",
    "- **Color-coded results**:\n",
    "  - Green background: Normal/safe text\n",
    "  - Red background: Hate speech detected\n",
    "- **Indonesian language support**: Interface uses both English and Indonesian\n",
    "- **Professional layout**: Clean, user-friendly design\n",
    "- **Real-time updates**: Statistics update as you type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233d9fd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. How to Use the Application\n",
    "\n",
    "### Step-by-Step Usage Guide\n",
    "\n",
    "#### Step 1: Launch the Application\n",
    "- Follow the instructions in Section 2 to start the GUI\n",
    "- Wait for the \"SUCCESS: Models loaded successfully\" message\n",
    "- The GUI window should appear automatically\n",
    "\n",
    "#### Step 2: Enter Text for Analysis\n",
    "1. **Click in the text input area**\n",
    "   - The placeholder text will disappear\n",
    "   - You can now type or paste your text\n",
    "\n",
    "2. **Input Indonesian text**\n",
    "   - The application works best with Indonesian language text\n",
    "   - You can enter anything from single words to multiple paragraphs\n",
    "   - Examples: comments, social media posts, articles, messages\n",
    "\n",
    "#### Step 3: Analyze the Text\n",
    "1. **Click the \"Analyze Text\" button**\n",
    "2. **Wait for processing** (usually 1-3 seconds)\n",
    "3. **View results** in the Analysis Results section\n",
    "\n",
    "#### Step 4: Interpret Results\n",
    "- Check the **prediction** (Normal vs Hate Speech)\n",
    "- Note the **confidence score** (higher is more certain)\n",
    "- Review **text statistics** for context\n",
    "\n",
    "### Quick Testing Options\n",
    "\n",
    "#### Use Example Text\n",
    "- Click **\"Example\"** to load sample text\n",
    "- Multiple examples available for testing\n",
    "- Good way to verify the application is working\n",
    "\n",
    "#### Clear and Reset\n",
    "- Click **\"Clear\"** to start over\n",
    "- Resets all text and results\n",
    "- Returns interface to initial state\n",
    "\n",
    "### Usage Tips\n",
    "\n",
    "#### Text Input Best Practices\n",
    "- **Language**: Use Indonesian text for best results\n",
    "- **Length**: Any length works, but longer texts may take more time\n",
    "- **Format**: Plain text works best (avoid complex formatting)\n",
    "\n",
    "#### Multiple Analyses\n",
    "- You can analyze different texts consecutively\n",
    "- No need to restart the application\n",
    "- Previous results are replaced with new ones\n",
    "\n",
    "#### Monitoring Performance\n",
    "- Check processing time to gauge system performance\n",
    "- Large texts or complex sentences may take longer\n",
    "- Confidence scores help assess result reliability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44461be1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Understanding Results\n",
    "\n",
    "### Classification Categories\n",
    "\n",
    "#### Normal Text\n",
    "- **Display**: Green background with \"Normal\" label\n",
    "- **Meaning**: Text is classified as non-offensive/safe\n",
    "- **Examples**: \n",
    "  - Regular conversations: \"Terima kasih atas bantuan Anda\"\n",
    "  - News articles: \"Pemerintah mengumumkan kebijakan baru\"\n",
    "  - Positive comments: \"Saya sangat menghargai pendapat Anda\"\n",
    "\n",
    "#### Hate Speech\n",
    "- **Display**: Red background with \"Hate Speech\" label  \n",
    "- **Meaning**: Text contains elements classified as hate speech\n",
    "- **Examples**: Text with abusive language, discriminatory content, or offensive material\n",
    "\n",
    "### Confidence Score Interpretation\n",
    "\n",
    "The confidence score shows how certain the model is about its prediction:\n",
    "\n",
    "- **90-100%**: Very High Confidence\n",
    "  - Model is very certain about the classification\n",
    "  - Results are highly reliable\n",
    "\n",
    "- **70-89%**: High Confidence  \n",
    "  - Model is fairly certain about the classification\n",
    "  - Results are generally reliable\n",
    "\n",
    "- **50-69%**: Moderate Confidence\n",
    "  - Model has some uncertainty\n",
    "  - Consider context and manual review\n",
    "\n",
    "- **Below 50%**: Low Confidence\n",
    "  - Model is uncertain about the classification\n",
    "  - Text may be ambiguous or edge case\n",
    "  - Manual review recommended\n",
    "\n",
    "### Text Statistics\n",
    "\n",
    "#### Character Count\n",
    "- Total characters including spaces and punctuation\n",
    "- Helps understand text length and complexity\n",
    "\n",
    "#### Word Count  \n",
    "- Number of words separated by spaces\n",
    "- Useful for understanding text density\n",
    "\n",
    "#### Sentence Count\n",
    "- Estimated number of sentences (based on punctuation)\n",
    "- Helps gauge text structure complexity\n",
    "\n",
    "#### Processing Time\n",
    "- Time taken for complete analysis (in seconds)\n",
    "- Includes text cleaning, vectorization, and prediction\n",
    "- Typical range: 0.1-3.0 seconds depending on text length\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "#### Model Limitations\n",
    "- **Training Data**: Model performance depends on training data coverage\n",
    "- **Context Sensitivity**: May miss subtle context or sarcasm\n",
    "- **Language Variants**: Works best with standard Indonesian\n",
    "- **Cultural Nuances**: May not capture all cultural references\n",
    "\n",
    "#### Best Practices for Interpretation\n",
    "1. **Consider confidence scores** when making decisions\n",
    "2. **Review low-confidence predictions** manually\n",
    "3. **Use text statistics** to understand processing complexity\n",
    "4. **Test with known examples** to validate behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a990d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "The Indonesian Hate Speech Detection GUI provides an intuitive interface for analyzing Indonesian text for hate speech content. \n",
    "\n",
    "### Quick Start Guide:\n",
    "\n",
    "1. **Navigate to notebooks directory**: `cd notebooks`\n",
    "2. **Run the application**: `python gui.py`\n",
    "3. **Wait for success message**: \"SUCCESS: Models loaded successfully\"\n",
    "4. **Use the GUI**: Enter Indonesian text and click \"Analyze Text\"\n",
    "\n",
    "### Key Features:\n",
    "- Real-time hate speech detection for Indonesian text\n",
    "- Confidence scoring (0-100%)\n",
    "- Text statistics (characters, words, sentences)\n",
    "- Color-coded results (green=normal, red=hate speech)\n",
    "- Processing time monitoring\n",
    "\n",
    "### Best Practices:\n",
    "- Use Indonesian language text for optimal results\n",
    "- Consider confidence scores when interpreting results\n",
    "- Test with example text to verify functionality\n",
    "- Processing typically takes 1-3 seconds\n",
    "\n",
    "For technical details about the underlying machine learning model, data processing, or training procedures, refer to the previous notebooks (01-04).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
